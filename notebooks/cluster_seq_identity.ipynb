{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Identity Split Creation\n",
    "\n",
    "This notebook creates the Sequence Identity split used to evaluate gRNAde on biologically dissimilar clusters of RNAs.\n",
    "We cluster the sequences based on nucleotide similarity using CD-HIT (Fu et al., 2012) with an identity threshold of 80% to create training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cd_hit_est(\n",
    "        input_sequences, \n",
    "        identity_threshold = 0.9,\n",
    "        word_size = 2,\n",
    "        input_file = \"input\",\n",
    "        output_file = \"output\"\n",
    "    ):\n",
    "    # https://manpages.ubuntu.com/manpages/impish/man1/cd-hit-est.1.html\n",
    "        \n",
    "    # Write input sequences to the temporary input file\n",
    "    SeqIO.write(input_sequences, input_file, \"fasta\")\n",
    "\n",
    "    # Run CD-HIT-EST\n",
    "    cmd = [\n",
    "        \"cd-hit-est\",\n",
    "        \"-i\", input_file,\n",
    "        \"-o\", output_file,\n",
    "        \"-c\", str(identity_threshold), # Sequence identity threshold (e.g., 90%)\n",
    "        \"-n\", str(word_size),          # Word size for sequence comparisson, larger is better (default: 2)\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "    # Read clustered sequences from the temporary output file\n",
    "    clustered_sequences = list(SeqIO.parse(output_file, \"fasta\"))\n",
    "\n",
    "    # Process the clustering output\n",
    "    seq_idx_to_cluster = {}\n",
    "    with open(output_file + \".clstr\", \"r\") as f:\n",
    "        current_cluster = None\n",
    "        for line in f:\n",
    "            if line.startswith(\">\"):\n",
    "                current_cluster = int(line.strip().split(\" \")[1])\n",
    "            else:\n",
    "                sequence_id = int(line.split(\">\")[1].split(\"...\")[0])\n",
    "                seq_idx_to_cluster[sequence_id] = current_cluster\n",
    "\n",
    "    # Delete temporary files\n",
    "    # os.remove(input_file)\n",
    "    # os.remove(output_file)\n",
    "    # os.remove(output_file + \".clstr\")\n",
    "\n",
    "    return clustered_sequences, seq_idx_to_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = torch.load(os.path.join(\"../data/\", \"processed.pt\"))\n",
    "seq_list = []\n",
    "\n",
    "for idx, data in enumerate(data_list):\n",
    "    seq = data[\"seq\"]\n",
    "    seq_list.append(SeqRecord(Seq(seq), id=str(idx)))  # the ID for each sequence is its index in data_list\n",
    "print(len(seq_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster at 80% sequence identity (lowest currently possible)\n",
    "clustered_sequences, seq_idx_to_cluster = run_cd_hit_est(seq_list, identity_threshold=0.8, word_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "len(clustered_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: it seems short sequences are not being clustered\n",
    "try:\n",
    "    # Why does this fail? Guess: sequences are too short?\n",
    "    assert len(seq_idx_to_cluster.keys()) == len(seq_list)\n",
    "except:\n",
    "    # Which sequence indices are not clustered? What are their corresponding sequences?\n",
    "    idx_not_clustered = list(set(list(range(len(data_list)))) - set(seq_idx_to_cluster.keys()))\n",
    "    print(\"Number of missing indices after clustering: \", len(idx_not_clustered))\n",
    "    \n",
    "    seq_lens = []\n",
    "    for idx in idx_not_clustered:\n",
    "        seq_lens.append(len(data_list[idx][\"seq\"]))\n",
    "    print(\"Sequence lengths for missing indices:\")\n",
    "    print(f\"    Distribution: {np.mean(seq_lens)} +- {np.std(seq_lens)}\")\n",
    "    print(f\"    Max: {np.max(seq_lens)}, Min: {np.min(seq_lens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sizes: number of sequences in each cluster\n",
    "cluster_ids, cluster_sizes = np.unique(list(seq_idx_to_cluster.values()), return_counts=True)\n",
    "for id, size in zip(cluster_ids[:10], cluster_sizes[:10]):\n",
    "    print(id, size)\n",
    "# Print some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_idx_to_cluster: (index in data_list: cluster ID)\n",
    "# (NEW) cluster_to_seq_idx_list: (cluster ID: list of indices in data_list)\n",
    "cluster_to_seq_idx_list = {}\n",
    "for seq_idx, cluster in seq_idx_to_cluster.items():\n",
    "    if cluster in cluster_to_seq_idx_list.keys():\n",
    "        cluster_to_seq_idx_list[cluster].append(seq_idx)\n",
    "    else:\n",
    "        cluster_to_seq_idx_list[cluster] = [seq_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sizes: number of structures (total) in each cluster\n",
    "cluster_sizes_structs = []\n",
    "for cluster, seq_idx_list in cluster_to_seq_idx_list.items():\n",
    "    count = 0\n",
    "    for seq_idx in seq_idx_list:\n",
    "        count += len(data_list[seq_idx]['coords_list'])\n",
    "    cluster_sizes_structs.append(count)\n",
    "\n",
    "# Cluster sequence size and structure size\n",
    "print(\"cluster ID, # sequences, total # structures\")\n",
    "for id, size, size_structs in zip(cluster_ids[:10], cluster_sizes[:10], cluster_sizes_structs[:10]):\n",
    "    print(id, size, size_structs)\n",
    "# Print some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx_list = []\n",
    "val_idx_list = []\n",
    "train_idx_list = []\n",
    "\n",
    "# Some heuristics\n",
    "# * Add samples to validation and test sets till their sizes are filled (200 samples), after which add everything to the train set\n",
    "# * Do not add very large seqeuence clusters (sizes > 100) to validation or test set\n",
    "# \n",
    "\n",
    "for cluster, seq_idx_list in cluster_to_seq_idx_list.items():\n",
    "    \n",
    "    if len(test_idx_list) < 200 and cluster_sizes[cluster] < 100:\n",
    "        test_idx_list += seq_idx_list\n",
    "    elif len(val_idx_list) < 200 and cluster_sizes[cluster] < 100:\n",
    "        val_idx_list += seq_idx_list\n",
    "    else:\n",
    "        train_idx_list += seq_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the sequences that were not assigned any clusters into the training set\n",
    "try:\n",
    "    assert len(test_idx_list) + len(val_idx_list) + len(train_idx_list) == len(data_list)\n",
    "except:\n",
    "    train_idx_list += idx_not_clustered\n",
    "    assert len(test_idx_list) + len(val_idx_list) + len(train_idx_list) == len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((train_idx_list, val_idx_list, test_idx_list), \"../data/seq_identity_split.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
